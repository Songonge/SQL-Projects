# 𝐏𝐫𝐨𝐣𝐞𝐜𝐭: 𝐃𝐚𝐭𝐚 𝐂𝐥𝐞𝐚𝐧𝐢𝐧𝐠 𝐟𝐨𝐫 𝐓𝐞𝐜𝐡𝐒𝐨𝐥𝐮𝐭𝐢𝐨𝐧𝐬 𝐋𝐭𝐝.

## 𝐓𝐚𝐛𝐥𝐞 𝐨𝐟 𝐂𝐨𝐧𝐭𝐞𝐧𝐭𝐬  
1. [Introduction](#𝐢𝐧𝐭𝐫𝐨𝐝𝐮𝐜𝐭𝐢𝐨𝐧)
2. [Importance of the Project](#𝐈𝐦𝐩𝐨𝐫𝐭𝐚𝐧𝐜𝐞-𝐨𝐟-𝐭𝐡𝐞-𝐏𝐫𝐨𝐣𝐞𝐜𝐭)
3. [Data Information](#𝐃𝐚𝐭𝐚-𝐈𝐧𝐟𝐨𝐫𝐦𝐚𝐭𝐢𝐨𝐧)
4. [Task 1: 𝐑𝐞𝐦𝐨𝐯𝐞 𝐃𝐮𝐩𝐥𝐢𝐜𝐚𝐭𝐞 𝐑𝐞𝐜𝐨𝐫𝐝𝐬](#𝐓𝐚𝐬𝐤-𝟏-𝐑𝐞𝐦𝐨𝐯𝐞-𝐃𝐮𝐩𝐥𝐢𝐜𝐚𝐭𝐞-𝐑𝐞𝐜𝐨𝐫𝐝𝐬)
5. [Task 2: 𝐅𝐢𝐱𝐞𝐝 𝐃𝐚𝐭𝐞 𝐅𝐨𝐫𝐦𝐚𝐭](#𝐓𝐚𝐬𝐤-𝟐-𝐅𝐢𝐱𝐞𝐝-𝐃𝐚𝐭𝐞-𝐅𝐨𝐫𝐦𝐚𝐭)
6. [Task 3: Checked and Removed Duplicates](#𝐓𝐚𝐬𝐤-𝟑-𝐂𝐡𝐞𝐜𝐤𝐞𝐝-𝐚𝐧𝐝-𝐑𝐞𝐦𝐨𝐯𝐞𝐝-𝐃𝐮𝐩𝐥𝐢𝐜𝐚𝐭𝐞𝐬)
7. [Task 4: Standardized the Data by Checking for Incorrect Spellings and Fixing them to Make all Data Consistent](#𝐓𝐚𝐬𝐤-𝟒-𝐒𝐭𝐚𝐧𝐝𝐚𝐫𝐝𝐢𝐳𝐞𝐝-𝐭𝐡𝐞-𝐃𝐚𝐭𝐚-𝐛𝐲-𝐜𝐡𝐞𝐜𝐤𝐢𝐧𝐠-𝐟𝐨𝐫-𝐢𝐧𝐜𝐨𝐫𝐫𝐞𝐜𝐭-𝐬𝐩𝐞𝐥𝐥𝐢𝐧𝐠𝐬-𝐚𝐧𝐝-𝐟𝐢𝐱𝐢𝐧𝐠-𝐭𝐡𝐞𝐦-𝐭𝐨-𝐦𝐚𝐤𝐞-𝐚𝐥𝐥-𝐝𝐚𝐭𝐚-𝐜𝐨𝐧𝐬𝐢𝐬𝐭𝐞𝐧𝐭)
8. [Task 5: Looked at NULL and Blank Values](#𝐓𝐚𝐬𝐤-𝟓-𝐋𝐨𝐨𝐤𝐞𝐝-𝐚𝐭-𝐍𝐔𝐋𝐋-𝐚𝐧𝐝-𝐁𝐥𝐚𝐧𝐤-𝐕𝐚𝐥𝐮𝐞𝐬)
9. [Task 6: Removed Unnecessary Rows and Columns](#𝐓𝐚𝐬𝐤-𝟔-𝐑𝐞𝐦𝐨𝐯𝐞𝐝-𝐔𝐧𝐧𝐞𝐜𝐞𝐬𝐬𝐚𝐫𝐲-𝐑𝐨𝐰𝐬-𝐚𝐧𝐝-𝐂𝐨𝐥𝐮𝐦𝐧𝐬)

## 𝐈𝐧𝐭𝐫𝐨𝐝𝐮𝐜𝐭𝐢𝐨𝐧
This project focuses on cleaning data for TechSolutions Ltd., which specializes in developing software products and services. Due to internal mismanagement and inconsistent data collection methods, the company has a lot of dirty data. 
Knowing that data cleaning is crucial in preparing data for analysis, the current project focuses on preparing the data for analysis. This will contribute to deriving meaningful insights and provide recommendations for the company to excel.

## 𝐈𝐦𝐩𝐨𝐫𝐭𝐚𝐧𝐜𝐞 𝐨𝐟 𝐭𝐡𝐞 𝐏𝐫𝐨𝐣𝐞𝐜𝐭
This project focuses on data cleaning to prepare a report on how long a project takes to be completed and how much was spent  on the project until completion. In what follows, a step-by-step description is provided of the data cleaning and transformation performed. 

## 𝐃𝐚𝐭𝐚 𝐈𝐧𝐟𝐨𝐫𝐦𝐚𝐭𝐢𝐨𝐧
The data provided contained the following information:
* Number of rows: 1800 rows  
* Number of columns: 10 columns

### Description of each column:
1. **project_id**: ID of the project
2. **project_name**: Name of the project
3. **start_date**: Date when the project started
4. **end_date**: Date when the project was completed (nullable)
5. **project_manager**: Name of the project manager
6. **team_members**: Team members involved in the project (comma-separated)
7. **status**: Current status of the project
8. **budget**: Budget allocated for the project
9. **expenditure**:  Money spent on the project
10. **client**: Name of the client company

> [!Important]
> I copied my raw data to a new table before starting the cleaning process. This was to ensure I have the original data to refer back to if you make a mistake or need to validate your changes later and to maintain data integrity! The following query was used:
```
DROP TABLE IF EXISTS [Learn SQL].dbo.tech_solutions_data1
SELECT * INTO [Learn SQL].dbo.tech_solutions_data1
FROM [Learn SQL].dbo.tech_solutions_data;
```

## 𝐓𝐚𝐬𝐤 𝟏: 𝐑𝐞𝐦𝐨𝐯𝐞 𝐃𝐮𝐩𝐥𝐢𝐜𝐚𝐭𝐞 𝐑𝐞𝐜𝐨𝐫𝐝𝐬 
In this task, I checked for columns having the same row twice using the query below:
```
SELECT *
FROM (
    SELECT
	ROW_NUMBER() OVER (PARTITION BY project_name, start_date, end_date, project_manager, team_members, status, budget, expenditure, client ORDER BY project_name) 
	AS dup_data 
    FROM [Learn SQL].dbo.tech_solutions_data1) AS num_of_dup_rows
WHERE dup_data > 1;
```

## 𝐓𝐚𝐬𝐤 𝟐: 𝐅𝐢𝐱𝐞𝐝 𝐃𝐚𝐭𝐞 𝐅𝐨𝐫𝐦𝐚𝐭
1. Checked for invalid date entries in the start_date column and corrected them.
```
UPDATE [Learn SQL].dbo.tech_solutions_data1
SET start_date = CONVERT(DATE, start_date);
```
> [!Note]
> After running this query, everything after the last digit of the date was transformed into zero. So, to update the date column permanently, I needed to alter the table and the start_date column.

2. To permanently store only the start_date without the time, I altered the start_date's data type.
```
ALTER TABLE [Learn SQL].dbo.tech_solutions_data1
ALTER COLUMN start_date DATE;
```
3. Checked for invalid date entries in the end_date column and corrected them.
```
UPDATE [Learn SQL].dbo.tech_solutions_data1
SET end_date = CONVERT(DATE, end_date);
```
2. To permanently store only the end_date without the time, I altered the end_date's data type.
```
ALTER TABLE [Learn SQL].dbo.tech_solutions_data1
ALTER COLUMN end_date DATE;
```


## 𝐓𝐚𝐬𝐤 𝟑: 𝐂𝐡𝐞𝐜𝐤𝐞𝐝 𝐚𝐧𝐝 𝐑𝐞𝐦𝐨𝐯𝐞𝐝 𝐃𝐮𝐩𝐥𝐢𝐜𝐚𝐭𝐞𝐬
Here I used `ROW_NUMBER()`, `OVER()`, `PARTITION BY`, and `ORDER BY` to identify duplicates in the data. To obtain best results, I partitioned by all the columns in the table. The output was inserted into a new table containing non-duplicate data. 

* **Checked for duplicates**
```
SELECT *
FROM (
    SELECT *,
		ROW_NUMBER() OVER (PARTITION BY company, location, industry, total_laid_off, percentage_laid_off, [date], stage, country, funds_raised_millions ORDER BY total_laid_off) AS dup_row_num
	FROM [Learn SQL].dbo.layoffs_working ) AS rem_duplicate_data
WHERE dup_row_num > 1;
```
> [!Note]
> I first wrote the query without the `ORDER BY` clause and this generated an error after executing it. Therefore, I realized that it is necessary when using the `ROW_NUMBER()` function in SQL Server. 

In the above query, I wrote the partition by over all the rows of the table to ensure that duplicates contain exact same rows. The query returned 5 rows (duplicates) from the data. Next, it was important to check further in writing query with the `WHERE` clause for each of those duplicate to verify if those were actually duplicates. Doing this save you from deleting rows that are not duplicates.

* **Removed duplicates**
To remove duplicates, I rewrote the above query. Then, inserted the output into a new table named layoffs_working2 containing non-duplicate rows. The query looked like:
```
SELECT * INTO [Learn SQL].dbo.layoffs_working2
FROM (
    SELECT *,
	ROW_NUMBER() OVER (PARTITION BY company, location, industry, total_laid_off, percentage_laid_off, [date], stage, country, funds_raised_millions ORDER BY total_laid_off) AS dup_row_num
    FROM [Learn SQL].dbo.layoffs_working ) AS rem_duplicate_data
WHERE dup_row_num = 1;
```
* **Selected all the data from the new table**
```
SELECT *
FROM [Learn SQL].dbo.layoffs_working2;
```
This last query selected all data from the new table named layoffs_working2 and returned 2356 rows.

## 𝐓𝐚𝐬𝐤 𝟒: 𝐒𝐭𝐚𝐧𝐝𝐚𝐫𝐝𝐢𝐳𝐞𝐝 𝐭𝐡𝐞 𝐃𝐚𝐭𝐚 𝐛𝐲 𝐜𝐡𝐞𝐜𝐤𝐢𝐧𝐠 𝐟𝐨𝐫 𝐢𝐧𝐜𝐨𝐫𝐫𝐞𝐜𝐭 𝐬𝐩𝐞𝐥𝐥𝐢𝐧𝐠𝐬 𝐚𝐧𝐝 𝐟𝐢𝐱𝐢𝐧𝐠 𝐭𝐡𝐞𝐦 𝐭𝐨 𝐦𝐚𝐤𝐞 𝐚𝐥𝐥 𝐝𝐚𝐭𝐚 𝐜𝐨𝐧𝐬𝐢𝐬𝐭𝐞𝐧𝐭.
The steps below were completed:

* **Trimmed the data to remove trailing space**
```
SELECT 
	company, 
	TRIM(company)
FROM [Learn SQL].dbo.layoffs_working2;
```

* **Updated the table with the trimmed columns**
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET company = TRIM(company);
```

* **Selected all the data from the updated table**
```
SELECT *
FROM [Learn SQL].dbo.layoffs_working2;
```

* **Checked for misspelled words in the industry column**
```
SELECT DISTINCT industry
FROM [Learn SQL].dbo.layoffs_working2;
```
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET industry = 'Crypto'
WHERE industry LIKE 'Crypto%';
```

* **Checked for misspelled words in the location column**
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET location = 'Malmo'
WHERE location LIKE 'Malmö';
```
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET location = 'Dusseldorf'
WHERE location LIKE 'Düsseldorf';
```
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET location = 'Florianopolis'
WHERE location LIKE 'Florianópolis';
```

* **Checked for misspelled words in the country column**
```
SELECT DISTINCT country
FROM [Learn SQL].dbo.layoffs_working2;
```
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET country = 'United States'
WHERE country LIKE 'United States%';
```

* **Converted the date column to the date type**
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET [date] = CAST([date] AS date)
WHERE [date] NOT LIKE 'NULL';
```
> [!Tip]
> You can select all the data from the table to confirm that everything has been updated accordingly.

## 𝐓𝐚𝐬𝐤 𝟓: 𝐋𝐨𝐨𝐤𝐞𝐝 𝐚𝐭 𝐍𝐔𝐋𝐋 𝐚𝐧𝐝 𝐁𝐥𝐚𝐧𝐤 𝐕𝐚𝐥𝐮𝐞𝐬 
This task helped in populating missing data where possible. I used the query below to convert every column with `'NULL'` (varchar data type) to `NULL` where the data type of that column was supposed to be int or float.
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET industry = NULL
WHERE industry = 'NULL';
```
This facilitated the conversion of those columns from string to int or float.  
I realized that SQL Server does not allow the `JOIN` clause in an `UPDATE` statement like in MySQL. So, I had to use a proper `FROM` clause to achieve the same functionality. The following steps were performed:

1. **Updated all the blanks with NULL**
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET industry = NULL
WHERE industry = '';
```

2. **Performed a self JOIN on the table to identify rows with NULL and empty rows**
```
SELECT l1.industry, l2.industry
FROM [Learn SQL].dbo.layoffs_working2 l1
JOIN [Learn SQL].dbo.layoffs_working2 l2
	ON l1.company = l2.company
WHERE (l1.industry IS NULL OR l1.industry = '')
AND l2.industry IS NOT NULL;
```

3. **Updated the table by replacing the table on the left side of the JOIN with the values from the table on the right**
```
UPDATE l1
SET l1.industry = l2.industry
FROM [Learn SQL].dbo.layoffs_working2 l1
JOIN [Learn SQL].dbo.layoffs_working2 l2
    ON l1.company = l2.company
WHERE l1.industry IS NULL
  AND l2.industry IS NOT NULL;
```
> [!Note]
> The queries in steps 1, 2 and 3 could be written using CTEs. This was used in the video by [Alex the Analyst](https://www.youtube.com/watch?v=4UltKCnnnTA).

## 𝐓𝐚𝐬𝐤 𝟔: 𝐑𝐞𝐦𝐨𝐯𝐞𝐝 𝐔𝐧𝐧𝐞𝐜𝐞𝐬𝐬𝐚𝐫𝐲 𝐑𝐨𝐰𝐬 𝐚𝐧𝐝 𝐂𝐨𝐥𝐮𝐦𝐧𝐬 
This task served to remove rows and columns that did not add any value to the entire dataset or that would not be needed in the ETL (Extract, Transform, Load) process.
Here I removed the dup_row_num column that was created while identifying duplicates in the data. The following query was used:
```
ALTER TABLE [Learn SQL].dbo.layoffs_working2
DROP COLUMN dup_row_num;
```
The query below allowed to identify NULL in the columns named total_laid_off and percentage_laid_off. The output was 361 rows. Knowing that the raw data was 2361 rows, then 2356 after removing duplicates. Therefore, these rows cannot just be deleted, but will be anlayzed in the second part of the project while identifying trends and patterns in the entire data during the exploratory data analysis.
```
SELECT * 
FROM [Learn SQL].dbo.layoffs_working2
WHERE total_laid_off IS NULL AND percentage_laid_off IS NULL;
```


<br/>
   
**Thank you for taking the time to read this report!**

**Please reach out for any updates.**

### Author
[Edwige Songong](https://github.com/Songonge)













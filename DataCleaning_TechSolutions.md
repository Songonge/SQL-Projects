# ğğ«ğ¨ğ£ğğœğ­: ğƒğšğ­ğš ğ‚ğ¥ğğšğ§ğ¢ğ§ğ  ğŸğ¨ğ« ğ“ğğœğ¡ğ’ğ¨ğ¥ğ®ğ­ğ¢ğ¨ğ§ğ¬ ğ‹ğ­ğ.

## ğ“ğšğ›ğ¥ğ ğ¨ğŸ ğ‚ğ¨ğ§ğ­ğğ§ğ­ğ¬  
1. [Introduction](#ğ¢ğ§ğ­ğ«ğ¨ğğ®ğœğ­ğ¢ğ¨ğ§)
2. [Importance of the Project](#ğˆğ¦ğ©ğ¨ğ«ğ­ğšğ§ğœğ-ğ¨ğŸ-ğ­ğ¡ğ-ğğ«ğ¨ğ£ğğœğ­)
3. [Data Information](#ğƒğšğ­ğš-ğˆğ§ğŸğ¨ğ«ğ¦ğšğ­ğ¢ğ¨ğ§)
4. [Task 1: ğ‘ğğ¦ğ¨ğ¯ğ ğƒğ®ğ©ğ¥ğ¢ğœğšğ­ğ ğ‘ğğœğ¨ğ«ğğ¬](#ğ“ğšğ¬ğ¤-ğŸ-ğ‘ğğ¦ğ¨ğ¯ğ-ğƒğ®ğ©ğ¥ğ¢ğœğšğ­ğ-ğ‘ğğœğ¨ğ«ğğ¬)
5. [Task 2: ğ…ğ¢ğ±ğğ ğƒğšğ­ğ ğ…ğ¨ğ«ğ¦ğšğ­](#ğ“ğšğ¬ğ¤-ğŸ-ğ…ğ¢ğ±ğğ-ğƒğšğ­ğ-ğ…ğ¨ğ«ğ¦ğšğ­)
6. [Task 3: Checked and Removed Duplicates](#ğ“ğšğ¬ğ¤-ğŸ‘-ğ‚ğ¡ğğœğ¤ğğ-ğšğ§ğ-ğ‘ğğ¦ğ¨ğ¯ğğ-ğƒğ®ğ©ğ¥ğ¢ğœğšğ­ğğ¬)
7. [Task 4: Standardized the Data by Checking for Incorrect Spellings and Fixing them to Make all Data Consistent](#ğ“ğšğ¬ğ¤-ğŸ’-ğ’ğ­ğšğ§ğğšğ«ğğ¢ğ³ğğ-ğ­ğ¡ğ-ğƒğšğ­ğš-ğ›ğ²-ğœğ¡ğğœğ¤ğ¢ğ§ğ -ğŸğ¨ğ«-ğ¢ğ§ğœğ¨ğ«ğ«ğğœğ­-ğ¬ğ©ğğ¥ğ¥ğ¢ğ§ğ ğ¬-ğšğ§ğ-ğŸğ¢ğ±ğ¢ğ§ğ -ğ­ğ¡ğğ¦-ğ­ğ¨-ğ¦ğšğ¤ğ-ğšğ¥ğ¥-ğğšğ­ğš-ğœğ¨ğ§ğ¬ğ¢ğ¬ğ­ğğ§ğ­)
8. [Task 5: Looked at NULL and Blank Values](#ğ“ğšğ¬ğ¤-ğŸ“-ğ‹ğ¨ğ¨ğ¤ğğ-ğšğ­-ğğ”ğ‹ğ‹-ğšğ§ğ-ğğ¥ğšğ§ğ¤-ğ•ğšğ¥ğ®ğğ¬)
9. [Task 6: Removed Unnecessary Rows and Columns](#ğ“ğšğ¬ğ¤-ğŸ”-ğ‘ğğ¦ğ¨ğ¯ğğ-ğ”ğ§ğ§ğğœğğ¬ğ¬ğšğ«ğ²-ğ‘ğ¨ğ°ğ¬-ğšğ§ğ-ğ‚ğ¨ğ¥ğ®ğ¦ğ§ğ¬)

## ğˆğ§ğ­ğ«ğ¨ğğ®ğœğ­ğ¢ğ¨ğ§
This project focuses on cleaning data for TechSolutions Ltd., which specializes in developing software products and services. Due to internal mismanagement and inconsistent data collection methods, the company has a lot of dirty data. 
Knowing that data cleaning is crucial in preparing data for analysis, the current project focuses on preparing the data for analysis. This will contribute to deriving meaningful insights and provide recommendations for the company to excel.

## ğˆğ¦ğ©ğ¨ğ«ğ­ğšğ§ğœğ ğ¨ğŸ ğ­ğ¡ğ ğğ«ğ¨ğ£ğğœğ­
This project focuses on data cleaning to prepare a report on how long a project takes to be completed and how much was spent  on the project until completion. In what follows, a step-by-step description is provided of the data cleaning and transformation performed. 

## ğƒğšğ­ğš ğˆğ§ğŸğ¨ğ«ğ¦ğšğ­ğ¢ğ¨ğ§
The data provided contained the following information:
* Number of rows: 1800 rows  
* Number of columns: 10 columns

### Description of each column:
1. **project_id**: ID of the project
2. **project_name**: Name of the project
3. **start_date**: Date when the project started
4. **end_date**: Date when the project was completed (nullable)
5. **project_manager**: Name of the project manager
6. **team_members**: Team members involved in the project (comma-separated)
7. **status**: Current status of the project
8. **budget**: Budget allocated for the project
9. **expenditure**:  Money spent on the project
10. **client**: Name of the client company

> [!Important]
> I copied my raw data to a new table before starting the cleaning process. This was to ensure I have the original data to refer back to if you make a mistake or need to validate your changes later and to maintain data integrity! The following query was used:
```
DROP TABLE IF EXISTS [Learn SQL].dbo.tech_solutions_data1
SELECT * INTO [Learn SQL].dbo.tech_solutions_data1
FROM [Learn SQL].dbo.tech_solutions_data;
```

## ğ“ğšğ¬ğ¤ ğŸ: ğ‘ğğ¦ğ¨ğ¯ğğ ğƒğ®ğ©ğ¥ğ¢ğœğšğ­ğ ğ‘ğğœğ¨ğ«ğğ¬ 
In this task, I checked for columns having the same row twice using the query below:
```
SELECT *
FROM (
    SELECT
	ROW_NUMBER() OVER (PARTITION BY project_name, start_date, end_date, project_manager, team_members, status, budget, expenditure, client ORDER BY project_name) 
	AS dup_data 
    FROM [Learn SQL].dbo.tech_solutions_data1) AS num_of_dup_rows
WHERE dup_data > 1;
```

## ğ“ğšğ¬ğ¤ ğŸ: ğ…ğ¢ğ±ğğ ğƒğšğ­ğ ğ…ğ¨ğ«ğ¦ğšğ­

### For the start_date column

1. Checked for invalid date entries in the start_date column and corrected them.
```
UPDATE [Learn SQL].dbo.tech_solutions_data1
SET start_date = CONVERT(DATE, start_date);
```
> [!Note]
> After running this query, everything after the last digit of the date was transformed into zero. So, to update the date column permanently, I needed to alter the table and the start_date column.

2. To permanently store only the start_date without the time, I altered the start_date's data type.
```
ALTER TABLE [Learn SQL].dbo.tech_solutions_data1
ALTER COLUMN start_date DATE;
```

### For the end_date column
1. Checked for invalid date entries in the end_date column and corrected them.
```
UPDATE [Learn SQL].dbo.tech_solutions_data1
SET end_date = CONVERT(DATE, end_date);
```
2. To permanently store only the end_date without the time, I altered the end_date's data type.
```
ALTER TABLE [Learn SQL].dbo.tech_solutions_data1
ALTER COLUMN end_date DATE;
```

## ğ“ğšğ¬ğ¤ 3: ğ’ğ­ğšğ§ğğšğ«ğğ¢ğ³ğğ Text ğƒğšğ­ğš to fix spelling errors and ensure consistency
The steps below were completed:

* **Cleaned any leading/trailing whitespaces in project_manager and status.**
```
UPDATE [Learn SQL].dbo.tech_solutions_data1
SET project_manager = TRIM(TRAILING '' FROM project_manager);
```

* **Standardized values in the status column** 
```
UPDATE [Learn SQL].dbo.tech_solutions_data1
SET status = 'pending'
WHERE status = 'pennding';
```

* **Standardized capitalization for project_name**
```
UPDATE [Learn SQL].dbo.tech_solutions_data1
SET project_name = 'Data Warehouse'
WHERE project_name = 'DATA WAREHOUSE';
```

```
UPDATE [Learn SQL].dbo.tech_solutions_data1
SET project_name = 'App Development'
WHERE project_name = 'APP DEVELOPMENT';
```

```
UPDATE [Learn SQL].dbo.tech_solutions_data1
SET project_name = 'IoT Automation'
WHERE project_name = 'IOT AUTOMATION';
```

```
UPDATE [Learn SQL].dbo.tech_solutions_data1
SET project_name = 'Cloud Migration'
WHERE project_name = 'CLOUD MIGRATION';
```
> [!Tip]
> When done with the modifications, select all the data from the table to confirm that everything has been updated accordingly.

## ğ“ğšğ¬ğ¤ 4: ğ‹ğ¨ğ¨ğ¤ğğ ğšğ­ ğğ”ğ‹ğ‹ ğšğ§ğ ğğ¥ğšğ§ğ¤ ğ•ğšğ¥ğ®ğğ¬ 
This task helped in populating missing data where possible. 

1. Checked for missing values in columns such as end_date, budget, expenditure, and team_members.  
Here, I first identified NULL in each columns using the queries below.
```
SELECT *
FROM [Learn SQL].dbo.tech_solutions_data1
WHERE end_date IS NULL;
```

```
SELECT *
FROM [Learn SQL].dbo.tech_solutions_data1
WHERE budget IS NULL;
```

```
SELECT *
FROM [Learn SQL].dbo.tech_solutions_data1
WHERE expenditure IS NULL;
```

```
SELECT *
FROM [Learn SQL].dbo.tech_solutions_data1
WHERE team_members IS NULL;
```

2. For budget and expenditure columns, I filled in missing values with the average of those columns.  
   * Calculated the average of the budget column
```
SELECT 
	AVG(budget)
FROM [Learn SQL].dbo.tech_solutions_data1
WHERE budget IS NOT NULL;
```

   * Updated the table with the average of the budget column where budget is NULL
```
UPDATE [Learn SQL].dbo.tech_solutions_data1
SET budget = (
    SELECT 
        Round(AVG(budget), 0)
    FROM [Learn SQL].dbo.tech_solutions_data1
    WHERE budget IS NOT NULL)
WHERE budget IS NULL;
```

   * Calculated the average of the expenditure column
```
SELECT 
	AVG(expenditure)
FROM [Learn SQL].dbo.tech_solutions_data1
WHERE expenditure IS NOT NULL;
```

   * Updated the table with the average of the expenditure column where expenditure is NULL
```
UPDATE [Learn SQL].dbo.tech_solutions_data1
SET expenditure = (
    SELECT 
        Round(AVG(expenditure), 0)
    FROM [Learn SQL].dbo.tech_solutions_data1
    WHERE expenditure IS NOT NULL)
WHERE expenditure IS NULL;
```



3. **Updated the table by replacing the table on the left side of the JOIN with the values from the table on the right**
```
UPDATE l1
SET l1.industry = l2.industry
FROM [Learn SQL].dbo.layoffs_working2 l1
JOIN [Learn SQL].dbo.layoffs_working2 l2
    ON l1.company = l2.company
WHERE l1.industry IS NULL
  AND l2.industry IS NOT NULL;
```
> [!Note]
> The queries in steps 1, 2 and 3 could be written using CTEs. This was used in the video by [Alex the Analyst](https://www.youtube.com/watch?v=4UltKCnnnTA).

## ğ“ğšğ¬ğ¤ ğŸ”: ğ‘ğğ¦ğ¨ğ¯ğğ ğ”ğ§ğ§ğğœğğ¬ğ¬ğšğ«ğ² ğ‘ğ¨ğ°ğ¬ ğšğ§ğ ğ‚ğ¨ğ¥ğ®ğ¦ğ§ğ¬ 
This task served to remove rows and columns that did not add any value to the entire dataset or that would not be needed in the ETL (Extract, Transform, Load) process.
Here I removed the dup_row_num column that was created while identifying duplicates in the data. The following query was used:
```
ALTER TABLE [Learn SQL].dbo.layoffs_working2
DROP COLUMN dup_row_num;
```
The query below allowed to identify NULL in the columns named total_laid_off and percentage_laid_off. The output was 361 rows. Knowing that the raw data was 2361 rows, then 2356 after removing duplicates. Therefore, these rows cannot just be deleted, but will be anlayzed in the second part of the project while identifying trends and patterns in the entire data during the exploratory data analysis.
```
SELECT * 
FROM [Learn SQL].dbo.layoffs_working2
WHERE total_laid_off IS NULL AND percentage_laid_off IS NULL;
```


<br/>
   
**Thank you for taking the time to read this report!**

**Please reach out for any updates.**

### Author
[Edwige Songong](https://github.com/Songonge)













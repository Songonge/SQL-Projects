# Data Cleaning in SQL Server

## Introduction
This project focuses on data cleaning, a crucial step in preparing data for analysis. Mastering this process is essential for identifying trends and patterns in the data. It also simplifies the creation of dashboards and the development of reports to effectively communicate findings.

## Importance of the Project
In this project, I focused on data cleaning to prepare a report on total layoffs across various companies in different countries. I followed the tutorial by [Alex the Analyst](https://www.youtube.com/watch?v=4UltKCnnnTA), adapting the process from MySQL to SQL Server. Despite initial challenges, I successfully completed the project. Below, I provide a step-by-step description of the data cleaning and transformation tasks performed. 

As many of you know, some functions behave differently in MySQL compared to SQL Server. This difference made the start of this project a bit challenging, but Iâ€™m proud to have overcome those hurdles and successfully completed the project. Below, Iâ€™ll walk you through the step-by-step process of cleaning and transforming the data. 

### Data Information
The data was downloaded from the link provided by [Alex the Analyst](https://www.youtube.com/watch?v=4UltKCnnnTA).
* Number of rows: 2361 rows  
* Number of columns: 9 columns

## ð“ðšð¬ð¤ ðŸ: ðƒð¨ð°ð§ð¥ð¨ðšððžð ðšð§ð ðˆð¦ð©ð¨ð«ð­ðžð ðƒðšð­ðš ð¢ð§ð­ð¨ ð’ðð‹ ð’ðžð«ð¯ðžð« 
Initially, I used the Import Flat File option in SQL Server to import the data I downloaded from Alex Freberg's link, but I encountered an error I hadn't seen before. To troubleshoot, I watched a detailed YouTube tutorial by [ð“ðšð¢ðŠð®ð©](https://lnkd.in/gBbXR8Rz), which demonstrated how to use the Import Data option instead. Following the clear steps in the video, I successfully imported the data without any issues. During this first step, I previewed the data to have a broad idea of what needs to be done using:
```
SELECT * 
FROM [Learn SQL].dbo.layoffs;
```

## ð“ðšð¬ð¤ ðŸ: ð‚ð¨ð©ð¢ðžð ð­ð¡ðž ð‘ðšð° ðƒðšð­ðš ð­ð¨ ðš ððžð° ð“ðšð›ð¥ðž
**ðð¨ð­ðž**: Always create a copy of your raw data before starting the cleaning process. This ensures you have the original data to refer back to if you make a mistake or need to validate your changes later. It's a simple but essential practice for maintaining data integrity!

In SQL server, the command to create a table from an existing one is different from that in MySQL. To copy the table to a new one, I used the following query in SQL Server:
```
SELECT * INTO layoffs_working
FROM [Learn SQL].dbo.layoffs;
```

## ð“ðšð¬ð¤ ðŸ‘: ð‚ð¡ðžðœð¤ðžð ðšð§ð ð‘ðžð¦ð¨ð¯ðžð ðƒð®ð©ð¥ð¢ðœðšð­ðžð¬
Here I used `ROW_NUMBER()`, `OVER()`, `PARTITION BY`, and `ORDER BY` to identify duplicates in the data. To obtain best results, I partitioned by all the columns in the table. The output was inserted into a new table containing non-duplicate data. 

* ð‚ð¡ðžðœð¤ðžð for ðƒð®ð©ð¥ð¢ðœðšð­ðžð¬:
```
SELECT *
FROM (
    SELECT *,
		ROW_NUMBER() OVER (PARTITION BY company, location, industry, total_laid_off, percentage_laid_off, [date], stage, country, funds_raised_millions ORDER BY total_laid_off) AS dup_row_num
	FROM [Learn SQL].dbo.layoffs_working ) AS rem_duplicate_data
WHERE dup_row_num > 1;
```
**Note**: I first wrote the query without the `ORDER BY` clause and this generated an error after executing it. Therefore, I realized that it is necessary when using the `ROW_NUMBER()` function in SQL Server. 

In the above query, I wrote the partition by over all the rows of the table to ensure that duplicates contain exact same rows. The query returned 5 rows (duplicates) from the data. Next, it was important to check further in writing query with the `WHERE` clause for each of those duplicate to verify if those were actually duplicates. Doing this save you from deleting rows that are not duplicates.

* **Removed duplicates**
To remove duplicates, I rewrote the above query. Then, inserted the output into a new table named layoffs_working2 containing non-duplicate rows. The query looked like:
```
SELECT * INTO [Learn SQL].dbo.layoffs_working2
FROM (
    SELECT *,
	ROW_NUMBER() OVER (PARTITION BY company, location, industry, total_laid_off, percentage_laid_off, [date], stage, country, funds_raised_millions ORDER BY total_laid_off) AS dup_row_num
    FROM [Learn SQL].dbo.layoffs_working ) AS rem_duplicate_data
WHERE dup_row_num = 1;
```
* **Selected all the data from the new table**
```
SELECT *
FROM [Learn SQL].dbo.layoffs_working2;
```
This last query selected all data from the new table named layoffs_working2 and returned 2356 rows.

## ð“ðšð¬ð¤ ðŸ’: ð’ð­ðšð§ððšð«ðð¢ð³ðžð ð­ð¡ðž ðƒðšð­ðš ð›ð² ðœð¡ðžðœð¤ð¢ð§ð  ðŸð¨ð« ð¢ð§ðœð¨ð«ð«ðžðœð­ ð¬ð©ðžð¥ð¥ð¢ð§ð ð¬ ðšð§ð ðŸð¢ð±ð¢ð§ð  ð­ð¡ðžð¦ ð­ð¨ ð¦ðšð¤ðž ðšð¥ð¥ ððšð­ðš ðœð¨ð§ð¬ð¢ð¬ð­ðžð§ð­.
The steps below were completed:

* **Trimmed the data to remove trailing space**
```
SELECT 
	company, 
	TRIM(company)
FROM [Learn SQL].dbo.layoffs_working2;
```

* **Updated the table with the trimmed columns**
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET company = TRIM(company);
```

* **Selected all the data from the updated table**
```
SELECT *
FROM [Learn SQL].dbo.layoffs_working2;
```

Checked for misspelled words in the industry column
```
SELECT DISTINCT industry
FROM [Learn SQL].dbo.layoffs_working2;
```
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET industry = 'Crypto'
WHERE industry LIKE 'Crypto%';
```

* **Checked for misspelled words in the location column**
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET location = 'Malmo'
WHERE location LIKE 'MalmÃ¶';
```
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET location = 'Dusseldorf'
WHERE location LIKE 'DÃ¼sseldorf';
```
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET location = 'Florianopolis'
WHERE location LIKE 'FlorianÃ³polis';
```

* **Checked for misspelled words in the country column**
```
SELECT DISTINCT country
FROM [Learn SQL].dbo.layoffs_working2;
```
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET country = 'United States'
WHERE country LIKE 'United States%';
```

* **Converted the date column to the date type**
```
UPDATE [Learn SQL].dbo.layoffs_working2
SET [date] = CAST([date] AS date)
WHERE [date] NOT LIKE 'NULL';
```


## ð“ðšð¬ð¤ ðŸ“: ð‹ð¨ð¨ð¤ðžð ðšð­ ðð”ð‹ð‹ ðšð§ð ðð¥ðšð§ð¤ ð•ðšð¥ð®ðžð¬ 

## ð“ðšð¬ð¤ ðŸ”: ð‘ðžð¦ð¨ð¯ðžð ð”ð§ð§ðžðœðžð¬ð¬ðšð«ð² ð‘ð¨ð°ð¬ ðšð§ð ð‚ð¨ð¥ð®ð¦ð§ð¬ 

## Imported data into SQL Server. 
When I first imported the data into SQL Server using the option Import Flat File, I encountered an error. This was my first time encountering this error. From there, I watched a YouTube video by [TaiKup](https://www.youtube.com/watch?v=K5_u6Xrbl_s) which showed how to use another option, Import Data. The video was very explicit and after watching it I went on to apply the steps and was able to import my data without any errors.

Note: It is not advised to work on the raw dataset. Always copy the raw data and do all your cleaning from the copied data. This is good practice as you can refer to the raw data if at any stage of your data cleaning, you made a mistake.

During this first step, I previewed the data to have a broad idea of what needs to be done.

---> Copied the raw data to a new table
In SQL server, the command to create a table from an existing one is different from that in MySQL. I also explained this in one of my posts here on LinkedIn. To copy the table to a new one, I used the following query in SQL Server:
SELECT * INTO layoffs_working
FROM [Learn SQL].dbo.layoffs;

---> Previewed the data using 
SELECT * 
FROM [Learn SQL].dbo.layoffs;

---> Checked for duplicates
SELECT *
FROM (
    SELECT *,
		ROW_NUMBER() OVER (PARTITION BY company, location, industry, total_laid_off, percentage_laid_off, [date], stage, country, funds_raised_millions ORDER BY total_laid_off) AS dup_row_num
	FROM [Learn SQL].dbo.layoffs_working ) AS rem_duplicate_data
WHERE dup_row_num > 1;

Note: The ORDER BY clause is necessary when using the ROW_NUMBER() function in SQL Server. Therefore, if you write the above query without the ORDER BY clause it will return an error. 

In the above query, we wrote the partition by over all the rows of the table to ensure that duplicates contain exact same rows. The query returned 5 rows (duplicates) from the data. Now, it is important to check further in writing query with the WHERE clause for each of those duplicate to verify if those are actually duplicates. This will save you from deleting rows that are not duplicates.

---> Removed duplicates in the data and created a new table to insert the non-duplicate data
To remove duplicates, I rewrote the above query. Then, inserted the output into a new table named layoffs_working2 containing non-duplicate rows. The query looked like:

SELECT * INTO [Learn SQL].dbo.layoffs_working2
FROM (
    SELECT *,
	ROW_NUMBER() OVER (PARTITION BY company, location, industry, total_laid_off, percentage_laid_off, [date], stage, country, funds_raised_millions ORDER BY total_laid_off) AS dup_row_num
    FROM [Learn SQL].dbo.layoffs_working ) AS rem_duplicate_data
WHERE dup_row_num = 1;

SELECT *
FROM [Learn SQL].dbo.layoffs_working2;

The last query selected all data from the new table named layoffs_working2 and returned 2356 rows.
 

---> Standardized the data for example by checking for incorrect spellings and fixing them to make all data consistent.

- Trimmed the data to remove trailing space
SELECT 
	company, 
	TRIM(company)
FROM [Learn SQL].dbo.layoffs_working2;

-- Updated the table with the trimmed columns
UPDATE [Learn SQL].dbo.layoffs_working2
SET company = TRIM(company);

SELECT *
FROM [Learn SQL].dbo.layoffs_working2;

-- Checked for misspelled words in the industry column
SELECT DISTINCT industry
FROM [Learn SQL].dbo.layoffs_working2;

UPDATE [Learn SQL].dbo.layoffs_working2
SET industry = 'Crypto'
WHERE industry LIKE 'Crypto%';

If you run the first query is this specific task, you will realized that every thing in the industry has been updated.

---> Looked at NULL and Blank values. This step helped in populating missing data where possible.
I used the query below to convert every column with 'NULL' to NULL where the data type of that column was supposed to be int or float.
UPDATE [Learn SQL].dbo.layoffs_working2
SET industry = NULL
WHERE industry = 'NULL';

This facilitated the conversion of those columns from string to int or float.


I realized that SQL Server does not allow th JOIN clause in an UPDATE statement like in MySQL. So, I had to use a proper FROM clause to achieve the same functionality.

The following steps were performed:
1. Updated all the blanks with NULL
UPDATE [Learn SQL].dbo.layoffs_working2
SET industry = NULL
WHERE industry = '';

2. Performed a self JOIN on the table to identify rows with NULL and empty rows.
SELECT l1.industry, l2.industry
FROM [Learn SQL].dbo.layoffs_working2 l1
JOIN [Learn SQL].dbo.layoffs_working2 l2
	ON l1.company = l2.company
WHERE (l1.industry IS NULL OR l1.industry = '')
AND l2.industry IS NOT NULL;

3. Updated the table by replacing the table on the left side of the JOIN with the values from the table on the right
UPDATE l1
SET l1.industry = l2.industry
FROM [Learn SQL].dbo.layoffs_working2 l1
JOIN [Learn SQL].dbo.layoffs_working2 l2
    ON l1.company = l2.company
WHERE l1.industry IS NULL
  AND l2.industry IS NOT NULL;


---> Removed unnecessary rows and columns that did not add any value to the entire dataset or that were not needed in the ETL (Extract, Transform, Load) process.
Here I removed the dup_row_num column that was created while identifying duplicates in the data. The following query was used:
ALTER TABLE [Learn SQL].dbo.layoffs_working2
DROP COLUMN dup_row_num;

Although there were still NULL values in the data, we left them for now as they could be explored in the next step which will be the exploratory data analysis.













